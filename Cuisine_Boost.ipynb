{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from clean_ingredients import clean_ingredients\n",
    "from remove_adj import remove_adj\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "get_ipython().magic(u'matplotlib inline')  \n",
    "data = json.load(open('/Users/guozhiqi-seven/Downloads/train.json')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modified_ingredients_per_cuisine(data):\n",
    "    IngrePerCuisineDict = {}\n",
    "    cuisines = []\n",
    "    all_ingredients = []\n",
    "    \n",
    "    for i in range(len(data)):       \n",
    "        thiscuisine = data[i]['cuisine']\n",
    "        \n",
    "        #pre-clean \n",
    "        thisingredients = data[i]['ingredients']\n",
    "        #thisingredients = remove_adj(thisingredients)\n",
    "        #thisingredients = clean_ingredients(thisingredients)    \n",
    "        \n",
    "        if thiscuisine not in IngrePerCuisineDict.keys():\n",
    "            cuisines.append(thiscuisine)\n",
    "            IngrePerCuisineDict[thiscuisine] = thisingredients           \n",
    "        else: \n",
    "            ingrelist = IngrePerCuisineDict[thiscuisine]\n",
    "            ingrelist.extend(thisingredients)\n",
    "            IngrePerCuisineDict[thiscuisine] = ingrelist\n",
    "                 \n",
    "        all_ingredients.extend(thisingredients)\n",
    "        \n",
    "    all_ingredients = list(set(all_ingredients)) # unique list of ALL ingredients\n",
    "    num_unique = len(all_ingredients)\n",
    "    num_cuisines = len(cuisines)\n",
    "    \n",
    "    return IngrePerCuisineDict,cuisines,num_unique,num_cuisines,all_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IngrePerCuisineDict,cuisines,num_unique,num_cuisines,all_ingredients=modified_ingredients_per_cuisine(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beef base', 'accent', 'ground peppercorn', 'chicharron', 'squid tube']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ingredients[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modified_count_matrix_recipe(data,all_ingredients): \n",
    "    tfm = np.zeros((len(data),len(all_ingredients)))    \n",
    "    for ii in range(len(data)):       \n",
    "        thisrecipe = data[ii]['ingredients']\n",
    "        thisrecipe = remove_adj(thisrecipe)\n",
    "        thisrecipe = clean_ingredients(thisrecipe)\n",
    "        for ingredient in thisrecipe:\n",
    "            if ingredient in all_ingredients:\n",
    "                jj = all_ingredients.index(ingredient) \n",
    "                tfm[ii,jj] += 1\n",
    "    return tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean&Stemming all ingredients\n",
    "#Remove unnecessary numbers&symbols&blank space\n",
    "#Causion: One should using remove_adj first then clean_ingredients\n",
    "#Reduced ingredients to 4538\n",
    "\n",
    "all_ingredients = remove_adj(all_ingredients)\n",
    "all_ingredients = clean_ingredients(all_ingredients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recipe_tfm=modified_count_matrix_recipe(data,all_ingredients)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfm_tfidf(tfm):\n",
    "    countsMatrix = sparse.csr_matrix(tfm)\n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(tfm)  \n",
    "    return tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.load(open('/Users/guozhiqi-seven/Downloads/train.json')) \n",
    "train_cuisine = [recipe['cuisine'] for recipe in data]\n",
    "recipe_length = [len(recipe['ingredients']) for recipe in data]\n",
    "labelencoder = LabelEncoder()\n",
    "cuisine_label = labelencoder.fit_transform(train_cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfm_recipe_tfidf = tfm_tfidf(recipe_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding recipe length to the matrix\n",
    "recipe_length = np.array(recipe_length)\n",
    "X_data = np.hstack((tfm_recipe_tfidf.toarray(),recipe_length.reshape(len(recipe_length),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 暂时不跑 ++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_size =  0.03333333333333333 Score: 0.781297134238\n",
      "test_size =  0.06666666666666667 Score: 0.78431372549\n",
      "test_size =  0.1 Score: 0.782302664656\n",
      "test_size =  0.13333333333333333 Score: 0.779411764706\n",
      "test_size =  0.16666666666666666 Score: 0.781867551667\n",
      "test_size =  0.2 Score: 0.782023884349\n",
      "test_size =  0.23333333333333334 Score: 0.781165822648\n",
      "test_size =  0.26666666666666666 Score: 0.776562647308\n",
      "test_size =  0.3 Score: 0.77432330512\n",
      "test_size =  0.3333333333333333 Score: 0.776587720622\n",
      "test_size =  0.36666666666666664 Score: 0.772970378497\n",
      "test_size =  0.4 Score: 0.772030169705\n",
      "test_size =  0.43333333333333335 Score: 0.769087955442\n",
      "test_size =  0.4666666666666667 Score: 0.768990410516\n",
      "test_size =  0.5 Score: 0.766430331372\n",
      "test_size =  0.5333333333333333 Score: 0.765191156366\n",
      "test_size =  0.5666666666666667 Score: 0.762633657216\n",
      "test_size =  0.6 Score: 0.761282212445\n",
      "test_size =  0.6333333333333333 Score: 0.760112738677\n",
      "test_size =  0.6666666666666666 Score: 0.75512897873\n",
      "test_size =  0.7 Score: 0.75048487896\n",
      "test_size =  0.7333333333333333 Score: 0.745885902359\n",
      "test_size =  0.7666666666666666 Score: 0.742080409261\n",
      "test_size =  0.8 Score: 0.738277812696\n",
      "test_size =  0.8333333333333334 Score: 0.727259013426\n",
      "test_size =  0.8666666666666667 Score: 0.719648400104\n",
      "test_size =  0.9 Score: 0.70698661899\n",
      "test_size =  0.9333333333333333 Score: 0.686259192414\n",
      "test_size =  0.9666666666666667 Score: 0.643969934199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "test_size = [1/30*x for x in list(range(1,30))]\n",
    "LOG = []\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "#X_train_tfidf = tfidf_transformer.fit_transform(X_data)\n",
    "\n",
    "for test in test_size:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,cuisine_label,\\\n",
    "                                                    test_size=test,random_state=0)\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    y_test = labelencoder.transform(y_test)    \n",
    "    LogReg = LogisticRegression(C=10)\n",
    "    LogReg = LogReg.fit(X_train,y_train) \n",
    "    print('test_size = ',test, 'Score:',LogReg.score(X_test, y_test) )\n",
    "    LOG.append(LogReg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thefile = open('Feature_Engineering_LR.txt', 'w')\n",
    "for item in LOG:\n",
    "    thefile.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 空隙++++++++++++++++++++++++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                    cuisine_label,test_size=0.25,random_state=0,stratify=cuisine_label)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.001 Score: 0.286705551086\n",
      "C =  0.01 Score: 0.455048270314\n",
      "C =  0.1 Score: 0.654967819791\n",
      "C =  1 Score: 0.748793242156\n",
      "C =  10 Score: 0.766894609815\n",
      "C =  100 Score: 0.753419147224\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "C_penalty = [10**i for i in range(-3,3)]\n",
    "for C_para in C_penalty:\n",
    "    LogReg = LogisticRegression(C=C_para)\n",
    "    LogReg = LogReg.fit(X_train,y_train) \n",
    "    print('C = ',C_para, 'Score:',LogReg.score(X_test, y_test) ) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "#from xgboost import XGBClassifier  \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                    cuisine_label,test_size=0.25,random_state=0,stratify=cuisine_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(X_train, label=y_train)\n",
    "xgb_test = xgb.DMatrix(X_test, label=y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.454408\ttest-merror:0.478781\n",
      "Multiple eval metrics have been passed: 'test-merror' will be used for early stopping.\n",
      "\n",
      "Will train until test-merror hasn't improved in 80 rounds.\n",
      "[1]\ttrain-merror:0.412169\ttest-merror:0.438656\n",
      "predicting, classification error=0.438656\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "param = {}\n",
    "#use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.008\n",
    "param['max_depth'] = 15\n",
    "param['silent'] = 1\n",
    "param['min_child_weight'] = 8\n",
    "param[\"subsample\"] = 0.7\n",
    "param[\"colsample_bytree\"] = 0.7\n",
    "param['nthread'] = 1\n",
    "param['num_class'] = 20\n",
    "\n",
    "watchlist = [ (xgb_train,'train'), (xgb_test, 'test') ]\n",
    "num_round = 2\n",
    "bst = xgb.train(param, xgb_train, num_round, watchlist, early_stopping_rounds=80);\n",
    "# get prediction\n",
    "pred = bst.predict(xgb_test);\n",
    "print ('predicting, classification error=%f' % (sum( int(pred[i]) != y_test[i] for i in range(len(y_test))) / float(len(y_test))))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.418706\ttest-merror:0.447908\n",
      "[1]\ttrain-merror:0.351257\ttest-merror:0.392498\n",
      "[2]\ttrain-merror:0.32464\ttest-merror:0.370977\n",
      "[3]\ttrain-merror:0.315018\ttest-merror:0.364642\n",
      "[4]\ttrain-merror:0.302179\ttest-merror:0.357804\n",
      "[5]\ttrain-merror:0.293765\ttest-merror:0.349356\n",
      "[6]\ttrain-merror:0.283305\ttest-merror:0.343624\n",
      "[7]\ttrain-merror:0.276064\ttest-merror:0.340306\n",
      "[8]\ttrain-merror:0.26822\ttest-merror:0.337188\n",
      "[9]\ttrain-merror:0.261046\ttest-merror:0.334875\n",
      "[10]\ttrain-merror:0.25538\ttest-merror:0.332462\n",
      "[11]\ttrain-merror:0.248575\ttest-merror:0.327534\n",
      "[12]\ttrain-merror:0.24462\ttest-merror:0.325121\n",
      "[13]\ttrain-merror:0.239859\ttest-merror:0.321098\n",
      "[14]\ttrain-merror:0.234462\ttest-merror:0.318685\n",
      "[15]\ttrain-merror:0.229098\ttest-merror:0.314863\n",
      "[16]\ttrain-merror:0.224472\ttest-merror:0.313355\n",
      "[17]\ttrain-merror:0.220617\ttest-merror:0.310036\n",
      "[18]\ttrain-merror:0.216996\ttest-merror:0.307824\n",
      "[19]\ttrain-merror:0.213845\ttest-merror:0.306114\n",
      "[20]\ttrain-merror:0.209889\ttest-merror:0.303399\n",
      "[21]\ttrain-merror:0.207275\ttest-merror:0.302293\n",
      "[22]\ttrain-merror:0.204257\ttest-merror:0.302293\n",
      "[23]\ttrain-merror:0.200872\ttest-merror:0.30008\n",
      "[24]\ttrain-merror:0.19772\ttest-merror:0.299276\n",
      "[25]\ttrain-merror:0.195005\ttest-merror:0.297365\n",
      "[26]\ttrain-merror:0.192088\ttest-merror:0.294549\n",
      "[27]\ttrain-merror:0.18887\ttest-merror:0.294147\n",
      "[28]\ttrain-merror:0.187026\ttest-merror:0.292035\n",
      "[29]\ttrain-merror:0.184479\ttest-merror:0.292035\n",
      "[30]\ttrain-merror:0.182065\ttest-merror:0.291231\n",
      "[31]\ttrain-merror:0.179383\ttest-merror:0.290326\n",
      "[32]\ttrain-merror:0.177774\ttest-merror:0.289622\n",
      "[33]\ttrain-merror:0.175696\ttest-merror:0.288214\n",
      "[34]\ttrain-merror:0.17345\ttest-merror:0.287007\n",
      "[35]\ttrain-merror:0.171505\ttest-merror:0.2858\n",
      "[36]\ttrain-merror:0.168823\ttest-merror:0.285901\n",
      "[37]\ttrain-merror:0.166745\ttest-merror:0.284996\n",
      "[38]\ttrain-merror:0.164834\ttest-merror:0.285398\n",
      "[39]\ttrain-merror:0.16356\ttest-merror:0.284594\n",
      "[40]\ttrain-merror:0.161214\ttest-merror:0.283789\n",
      "[41]\ttrain-merror:0.159873\ttest-merror:0.282482\n",
      "[42]\ttrain-merror:0.158465\ttest-merror:0.281476\n",
      "[43]\ttrain-merror:0.157291\ttest-merror:0.28027\n",
      "[44]\ttrain-merror:0.156017\ttest-merror:0.279364\n",
      "[45]\ttrain-merror:0.154308\ttest-merror:0.279163\n",
      "[46]\ttrain-merror:0.152799\ttest-merror:0.279364\n",
      "[47]\ttrain-merror:0.150922\ttest-merror:0.278962\n",
      "[48]\ttrain-merror:0.14995\ttest-merror:0.278761\n",
      "[49]\ttrain-merror:0.148676\ttest-merror:0.278158\n",
      "[50]\ttrain-merror:0.147\ttest-merror:0.278359\n",
      "[51]\ttrain-merror:0.145592\ttest-merror:0.278459\n",
      "[52]\ttrain-merror:0.144251\ttest-merror:0.277454\n",
      "[53]\ttrain-merror:0.142742\ttest-merror:0.276146\n",
      "[54]\ttrain-merror:0.141636\ttest-merror:0.275644\n",
      "[55]\ttrain-merror:0.140764\ttest-merror:0.275744\n",
      "[56]\ttrain-merror:0.139155\ttest-merror:0.274739\n",
      "[57]\ttrain-merror:0.138351\ttest-merror:0.274135\n",
      "[58]\ttrain-merror:0.137144\ttest-merror:0.273733\n",
      "[59]\ttrain-merror:0.136574\ttest-merror:0.274035\n",
      "[60]\ttrain-merror:0.135065\ttest-merror:0.273029\n",
      "[61]\ttrain-merror:0.133959\ttest-merror:0.272526\n",
      "[62]\ttrain-merror:0.133088\ttest-merror:0.272224\n",
      "[63]\ttrain-merror:0.131814\ttest-merror:0.271621\n",
      "[64]\ttrain-merror:0.130774\ttest-merror:0.271118\n",
      "[65]\ttrain-merror:0.129903\ttest-merror:0.271118\n",
      "[66]\ttrain-merror:0.129098\ttest-merror:0.271118\n",
      "[67]\ttrain-merror:0.128126\ttest-merror:0.270314\n",
      "[68]\ttrain-merror:0.126785\ttest-merror:0.269509\n",
      "[69]\ttrain-merror:0.125947\ttest-merror:0.268906\n",
      "[70]\ttrain-merror:0.125545\ttest-merror:0.268101\n",
      "[71]\ttrain-merror:0.124304\ttest-merror:0.267397\n",
      "[72]\ttrain-merror:0.123433\ttest-merror:0.267599\n",
      "[73]\ttrain-merror:0.122695\ttest-merror:0.266995\n",
      "[74]\ttrain-merror:0.121991\ttest-merror:0.266794\n",
      "[75]\ttrain-merror:0.121153\ttest-merror:0.266794\n",
      "[76]\ttrain-merror:0.119946\ttest-merror:0.26609\n",
      "[77]\ttrain-merror:0.119108\ttest-merror:0.265788\n",
      "[78]\ttrain-merror:0.118203\ttest-merror:0.265487\n",
      "[79]\ttrain-merror:0.117164\ttest-merror:0.264984\n",
      "[80]\ttrain-merror:0.115957\ttest-merror:0.264381\n",
      "[81]\ttrain-merror:0.11532\ttest-merror:0.264179\n",
      "[82]\ttrain-merror:0.114247\ttest-merror:0.263475\n",
      "[83]\ttrain-merror:0.113543\ttest-merror:0.263375\n",
      "[84]\ttrain-merror:0.113007\ttest-merror:0.263174\n",
      "[85]\ttrain-merror:0.111968\ttest-merror:0.26257\n",
      "[86]\ttrain-merror:0.111364\ttest-merror:0.261967\n",
      "[87]\ttrain-merror:0.110124\ttest-merror:0.261766\n",
      "[88]\ttrain-merror:0.109554\ttest-merror:0.262068\n",
      "[89]\ttrain-merror:0.108649\ttest-merror:0.261665\n",
      "[90]\ttrain-merror:0.107777\ttest-merror:0.261866\n",
      "[91]\ttrain-merror:0.107576\ttest-merror:0.262068\n",
      "[92]\ttrain-merror:0.106973\ttest-merror:0.262068\n",
      "[93]\ttrain-merror:0.106269\ttest-merror:0.262068\n",
      "[94]\ttrain-merror:0.105531\ttest-merror:0.261364\n",
      "[95]\ttrain-merror:0.104961\ttest-merror:0.261967\n",
      "[96]\ttrain-merror:0.104056\ttest-merror:0.261665\n",
      "[97]\ttrain-merror:0.103252\ttest-merror:0.26066\n",
      "[98]\ttrain-merror:0.102447\ttest-merror:0.260459\n",
      "[99]\ttrain-merror:0.101442\ttest-merror:0.260257\n",
      "[100]\ttrain-merror:0.100369\ttest-merror:0.260056\n",
      "[101]\ttrain-merror:0.099531\ttest-merror:0.259855\n",
      "[102]\ttrain-merror:0.098726\ttest-merror:0.260459\n",
      "[103]\ttrain-merror:0.098357\ttest-merror:0.260056\n",
      "[104]\ttrain-merror:0.097486\ttest-merror:0.259654\n",
      "[105]\ttrain-merror:0.096882\ttest-merror:0.259453\n",
      "[106]\ttrain-merror:0.096413\ttest-merror:0.259051\n",
      "[107]\ttrain-merror:0.095675\ttest-merror:0.25895\n",
      "[108]\ttrain-merror:0.095039\ttest-merror:0.257844\n",
      "[109]\ttrain-merror:0.094837\ttest-merror:0.257844\n",
      "[110]\ttrain-merror:0.094133\ttest-merror:0.257643\n",
      "[111]\ttrain-merror:0.093496\ttest-merror:0.257643\n",
      "[112]\ttrain-merror:0.092625\ttest-merror:0.256939\n",
      "[113]\ttrain-merror:0.091753\ttest-merror:0.256939\n",
      "[114]\ttrain-merror:0.091183\ttest-merror:0.256537\n",
      "[115]\ttrain-merror:0.09058\ttest-merror:0.257241\n",
      "[116]\ttrain-merror:0.089909\ttest-merror:0.256637\n",
      "[117]\ttrain-merror:0.089574\ttest-merror:0.256637\n",
      "[118]\ttrain-merror:0.089172\ttest-merror:0.255833\n",
      "[119]\ttrain-merror:0.088736\ttest-merror:0.256034\n",
      "[120]\ttrain-merror:0.087865\ttest-merror:0.255933\n",
      "[121]\ttrain-merror:0.087395\ttest-merror:0.255732\n",
      "[122]\ttrain-merror:0.086758\ttest-merror:0.255833\n",
      "[123]\ttrain-merror:0.086121\ttest-merror:0.254827\n",
      "[124]\ttrain-merror:0.08525\ttest-merror:0.254827\n",
      "[125]\ttrain-merror:0.084546\ttest-merror:0.255129\n",
      "[126]\ttrain-merror:0.084278\ttest-merror:0.254726\n",
      "[127]\ttrain-merror:0.08354\ttest-merror:0.254626\n",
      "[128]\ttrain-merror:0.083272\ttest-merror:0.254224\n",
      "[129]\ttrain-merror:0.082601\ttest-merror:0.254324\n",
      "[130]\ttrain-merror:0.082199\ttest-merror:0.254123\n",
      "[131]\ttrain-merror:0.081696\ttest-merror:0.253821\n",
      "[132]\ttrain-merror:0.081059\ttest-merror:0.254425\n",
      "[133]\ttrain-merror:0.080556\ttest-merror:0.253721\n",
      "[134]\ttrain-merror:0.080221\ttest-merror:0.254023\n",
      "[135]\ttrain-merror:0.079115\ttest-merror:0.25362\n",
      "[136]\ttrain-merror:0.078579\ttest-merror:0.253721\n",
      "[137]\ttrain-merror:0.07831\ttest-merror:0.253319\n",
      "[138]\ttrain-merror:0.077908\ttest-merror:0.253419\n",
      "[139]\ttrain-merror:0.077439\ttest-merror:0.253821\n",
      "[140]\ttrain-merror:0.076902\ttest-merror:0.253721\n",
      "[141]\ttrain-merror:0.0765\ttest-merror:0.253017\n",
      "[142]\ttrain-merror:0.076266\ttest-merror:0.252514\n",
      "[143]\ttrain-merror:0.075394\ttest-merror:0.252011\n",
      "[144]\ttrain-merror:0.074891\ttest-merror:0.252212\n",
      "[145]\ttrain-merror:0.074656\ttest-merror:0.253117\n",
      "[146]\ttrain-merror:0.074221\ttest-merror:0.253017\n",
      "[147]\ttrain-merror:0.073751\ttest-merror:0.252414\n",
      "[148]\ttrain-merror:0.073282\ttest-merror:0.252212\n",
      "[149]\ttrain-merror:0.072813\ttest-merror:0.252112\n",
      "[150]\ttrain-merror:0.072209\ttest-merror:0.250805\n",
      "[151]\ttrain-merror:0.07174\ttest-merror:0.250302\n",
      "[152]\ttrain-merror:0.071271\ttest-merror:0.250402\n",
      "[153]\ttrain-merror:0.070835\ttest-merror:0.249899\n",
      "[154]\ttrain-merror:0.070198\ttest-merror:0.250201\n",
      "[155]\ttrain-merror:0.069695\ttest-merror:0.250101\n",
      "[156]\ttrain-merror:0.06946\ttest-merror:0.249799\n",
      "[157]\ttrain-merror:0.068823\ttest-merror:0.249698\n",
      "[158]\ttrain-merror:0.068052\ttest-merror:0.249899\n",
      "[159]\ttrain-merror:0.067684\ttest-merror:0.249799\n",
      "[160]\ttrain-merror:0.067281\ttest-merror:0.250402\n",
      "[161]\ttrain-merror:0.067047\ttest-merror:0.250201\n",
      "[162]\ttrain-merror:0.067013\ttest-merror:0.25\n",
      "[163]\ttrain-merror:0.066443\ttest-merror:0.250402\n",
      "[164]\ttrain-merror:0.066108\ttest-merror:0.249799\n",
      "[165]\ttrain-merror:0.065605\ttest-merror:0.250201\n",
      "[166]\ttrain-merror:0.065203\ttest-merror:0.249799\n",
      "[167]\ttrain-merror:0.064801\ttest-merror:0.249296\n",
      "[168]\ttrain-merror:0.064465\ttest-merror:0.249397\n",
      "[169]\ttrain-merror:0.064063\ttest-merror:0.249095\n",
      "[170]\ttrain-merror:0.063694\ttest-merror:0.248793\n",
      "[171]\ttrain-merror:0.06346\ttest-merror:0.248592\n",
      "[172]\ttrain-merror:0.06289\ttest-merror:0.247989\n",
      "[173]\ttrain-merror:0.062588\ttest-merror:0.24829\n",
      "[174]\ttrain-merror:0.062253\ttest-merror:0.248391\n",
      "[175]\ttrain-merror:0.061985\ttest-merror:0.24829\n",
      "[176]\ttrain-merror:0.061716\ttest-merror:0.24819\n",
      "[177]\ttrain-merror:0.061448\ttest-merror:0.24819\n",
      "[178]\ttrain-merror:0.060677\ttest-merror:0.248693\n",
      "[179]\ttrain-merror:0.060275\ttest-merror:0.24829\n",
      "[180]\ttrain-merror:0.060107\ttest-merror:0.248492\n",
      "[181]\ttrain-merror:0.059806\ttest-merror:0.24829\n",
      "[182]\ttrain-merror:0.059537\ttest-merror:0.248089\n",
      "[183]\ttrain-merror:0.059169\ttest-merror:0.247989\n",
      "[184]\ttrain-merror:0.059068\ttest-merror:0.24819\n",
      "[185]\ttrain-merror:0.058833\ttest-merror:0.247687\n",
      "[186]\ttrain-merror:0.058498\ttest-merror:0.246883\n",
      "[187]\ttrain-merror:0.057895\ttest-merror:0.246681\n",
      "[188]\ttrain-merror:0.057492\ttest-merror:0.246983\n",
      "[189]\ttrain-merror:0.057425\ttest-merror:0.246782\n",
      "[190]\ttrain-merror:0.057157\ttest-merror:0.246782\n",
      "[191]\ttrain-merror:0.05699\ttest-merror:0.246782\n",
      "[192]\ttrain-merror:0.056621\ttest-merror:0.246078\n",
      "[193]\ttrain-merror:0.056319\ttest-merror:0.246078\n",
      "[194]\ttrain-merror:0.055649\ttest-merror:0.246078\n",
      "[195]\ttrain-merror:0.05538\ttest-merror:0.245676\n",
      "[196]\ttrain-merror:0.055079\ttest-merror:0.245575\n",
      "[197]\ttrain-merror:0.054576\ttest-merror:0.245475\n",
      "[198]\ttrain-merror:0.054073\ttest-merror:0.245475\n",
      "[199]\ttrain-merror:0.053738\ttest-merror:0.245575\n",
      "predicting, classification error=0.245575\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "\n",
    "param['bst:max_depth'] = 20\n",
    "param['bst:eta'] = 0.2\n",
    "param['silent'] = 0\n",
    "param['objective'] = 'multi:softmax'\n",
    "param['num_class'] = 20\n",
    "param['nthread'] = 2\n",
    "param['eval_metric'] = 'merror'\n",
    "\n",
    "watchlist = [(xgb_train,'train'), (xgb_test, 'test')]\n",
    "\n",
    "num_round = 200\n",
    "bst = xgb.train(param, xgb_train, num_round, watchlist)\n",
    "\n",
    "\n",
    "pred = bst.predict(xgb_test)\n",
    "print ('predicting, classification error=%f' % (sum( int(pred[i]) != y_test[i] for i in range(len(y_test))) / float(len(y_test))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 间隔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfm = modified_count_matrix_recipe(data,all_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_selection\n",
    "mutual_info = sklearn.feature_selection.mutual_info_classif(tfm,cuisine_label)\n",
    "mu = mutual_info.argsort()\n",
    "mutual_information = []\n",
    "for i in range(len(mu)):\n",
    "    mutual_information.append([mutual_info[mu[i]],mu[i]])\n",
    "top_mutual = (mutual_info.shape - sum(mutual_info == 0))\n",
    "index = [x[1] for x in mutual_information[-top_mutual:]]\n",
    "ingred_mutual = [list(ingredients)[ind] for ind in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
